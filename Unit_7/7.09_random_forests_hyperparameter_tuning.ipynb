{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373a8a63-82b4-4f04-a033-3ac13dc594da",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "- Identify the main benefits of Random Forest Algorithm\n",
    "- Perform Hyperparameter tuning\n",
    "- Rank Feature by Importance with Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f832fa6-77b9-4b72-bf1b-e8ca4f3892ef",
   "metadata": {},
   "source": [
    "#### Advantages of Random Forest\n",
    "- Scaling numerical features is not necessary\n",
    "- Important features in the data automatically shine through. The algorithm intrinsically takes care of feature selection to a large extent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6bfd6-c19e-4a34-a5c3-2e35fd9940b6",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "- In the previous class we implemented random forests but we used the default arguments. As discussed above there are a lot of parameters that can be modified to fine tune the algorithm even further, and hence improve the performance of the model.\n",
    "- This fine tuning the parameters of any algorithm is called Hyperparameter tuning. We would use a grid search cross-validation technique to accomplish this. We will discuss the code later.\n",
    "- Some parameters that can greatly affect the performance of random forests are mentioned below:\n",
    "\n",
    "```python\n",
    "n_estimators = [200, 500, 1000, 2000, 4000]\n",
    "min_samples_split = [2, 4, 8, 16, 32]\n",
    "min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "max_features = ['sqrt', 'log2']\n",
    "max_samples = ['None', 0.5, 0.8]\n",
    "```\n",
    "\n",
    "- This is also known as **grid search** as this can also be thought of a grid of possible combinations of all the different values of various parameters that we want to test. Basically the model is tested for each point on the grid and the best combination of values of the parameters is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e28a96-9d14-4a00-b07b-6269b9af0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "numerical = pd.read_csv('files_for_lesson_and_activities/numerical.csv')\n",
    "categorical = pd.read_csv('files_for_lesson_and_activities/categorical.csv')\n",
    "targets = pd.read_csv('files_for_lesson_and_activities/target.csv')\n",
    "\n",
    "encoder = OneHotEncoder(drop='first').fit(categorical)\n",
    "encoded_categorical = encoder.transform(categorical).toarray()\n",
    "encoded_categorical = pd.DataFrame(encoded_categorical)\n",
    "\n",
    "data = pd.concat([numerical, encoded_categorical, targets], axis = 1)\n",
    "regression_target = data['TARGET_D']\n",
    "# data.head()\n",
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis = 1)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis=1)\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "y_sm.value_counts()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.25, random_state=0)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "y_train_regression = X_train['TARGET_D']\n",
    "y_test_regression = X_test['TARGET_D']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e23c2-7b02-47d6-860d-3f68dd51ee40",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1d93f-1557-404a-8e1e-1bffbcf73224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 500, 1000],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf' : [1, 2],\n",
    "    'max_features': ['sqrt']\n",
    "#    'max_samples' : ['None', 0.5]\n",
    "    }\n",
    "clf = RandomForestClassifier(random_state=100)\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1)\n",
    "grid_search.fit(X_train,y_train)\n",
    "grid_search.best_params_ #To check the best set of parameters returned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18322a-dc7a-45e5-97fc-1b9128135629",
   "metadata": {},
   "source": [
    "- Here is a snapshot of the results: [link to the image - Grid Search CV Results](https://education-team-2020.s3-eu-west-1.amazonaws.com/data-analytics/7.09/7.09-grid_search_results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343e708-3e58-400c-969d-892452f4eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(random_state=0, max_features='sqrt', min_samples_leaf=1, min_samples_split=4, n_estimators=100)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c52e75-c5a3-4457-b6d4-4eddf4301704",
   "metadata": {},
   "source": [
    "**Grid Search** is an effective method for adjusting the parameters in supervised learning and improve the generalization performance of a model.</br>\n",
    "  **RandomizedSearchCV** is very useful when we have many parameters to try and the training time is very long.\n",
    "  Grid Search is good when we work with a small number of hyperparameters. However, if the number of parameters to consider is particularly high and the magnitudes of influence are imbalanced, the better choice is to use the Random Search.\n",
    "  [extra help](https://towardsdatascience.com/machine-learning-gridsearchcv-randomizedsearchcv-d36b89231b10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1713ee-8a00-484f-921e-7e0a22090d38",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "- It uses impurity-based feature importance measure\n",
    "- Higher the score, the more important the feature is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62dbf5-b7b3-42e8-b992-f2625b97f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit( X_train, y_train)\n",
    "X_train.head()\n",
    "feature_names = X_train.columns\n",
    "feature_names = list(feature_names)\n",
    "\n",
    "df = pd.DataFrame(list(zip(feature_names, clf.feature_importances_)))\n",
    "df.columns = ['columns_name', 'score_feature_importance']\n",
    "df.sort_values(by=['score_feature_importance'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864315e1-32e8-40e0-b5fd-a65f4dff78fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2495b8d-df6f-4dac-8c34-7b54b4d16013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d642c-c856-4dec-b6e4-b8756d4c571b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
